{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 安装必要包"
      ],
      "metadata": {
        "id": "XGvPFG-hCqbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install --quiet langchain sentence_transformers\n",
        "# %pip install --quiet scikit-learn numpy\n",
        "# %pip install --quiet langchain_huggingface"
      ],
      "metadata": {
        "id": "hys0j7XfFVoc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 模型选择"
      ],
      "metadata": {
        "id": "Z3qM3WcuCndI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('thenlper/gte-large-zh')"
      ],
      "metadata": {
        "id": "P1kzBRSbFY3p",
        "outputId": "a71f708f-a03e-4c2a-850c-c170f0be8494",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import top_k_accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sentence_transformers import util\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "Qo36Ili_ZTBc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 文本嵌入"
      ],
      "metadata": {
        "id": "avyaUz_qMvjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算QQP任务指标\n",
        "def evaluate_qqp(model, qqp_data):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    # 遍历所有数据项\n",
        "    for idx in range(len(qqp_data['question1'])):\n",
        "        question1 = qqp_data['question1'][idx]\n",
        "        question2 = qqp_data['question2'][idx]\n",
        "        label = qqp_data['label'][idx]\n",
        "\n",
        "        # 获取嵌入\n",
        "        embeddings_q1 = model.encode([question1])\n",
        "        embeddings_q2 = model.encode([question2])\n",
        "\n",
        "        # 计算余弦相似度\n",
        "        cosine_sim = cosine_similarity(embeddings_q1, embeddings_q2)[0][0]\n",
        "\n",
        "        # 判断相似性，余弦相似度 > 0.9 认为是相似\n",
        "        prediction = 1 if cosine_sim > 0.8 else 0\n",
        "\n",
        "        # 记录实际标签和预测标签\n",
        "        y_true.append(label)\n",
        "        y_pred.append(prediction)\n",
        "\n",
        "    # 计算准确率、召回率、精确率\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "\n",
        "    return acc, precision, recall"
      ],
      "metadata": {
        "id": "FrQSSGfyOaw1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算ANA任务的前1、前3准确率\n",
        "def evaluate_analogy(model, analogy_data):\n",
        "    correct_1 = 0\n",
        "    correct_2 = 0\n",
        "    correct_3 = 0\n",
        "\n",
        "    # 遍历所有数据项\n",
        "    for idx in range(len(analogy_data['stem'])):\n",
        "        stem = analogy_data['stem'][idx]\n",
        "        answer = analogy_data['answer'][idx]\n",
        "        choices = analogy_data['choice'][idx]\n",
        "\n",
        "        # 获取嵌入\n",
        "        embeddings_stem_1 = model.encode(stem[0])  # stem 第一个词的嵌入\n",
        "        embeddings_stem_2 = model.encode(stem[1])  # stem 第二个词的嵌入\n",
        "\n",
        "        # 计算stem两个词汇之间的相似度\n",
        "        cosine_sim_stem = cosine_similarity([embeddings_stem_1], [embeddings_stem_2])[0][0]\n",
        "\n",
        "        # 计算每个选项的相似度差值\n",
        "        cosine_differences = []\n",
        "        for choice in choices:\n",
        "            embeddings_choice_1 = model.encode(choice[0])  # 选项第一个词的嵌入\n",
        "            embeddings_choice_2 = model.encode(choice[1])  # 选项第二个词的嵌入\n",
        "\n",
        "            # 计算当前选项两个词的相似度\n",
        "            cosine_sim_choice = cosine_similarity([embeddings_choice_1], [embeddings_choice_2])[0][0]\n",
        "\n",
        "            # 计算与stem的相似度差值\n",
        "            cosine_diff = abs(cosine_sim_stem - cosine_sim_choice)\n",
        "            cosine_differences.append(cosine_diff)\n",
        "\n",
        "        # 获取按相似度差值排序后的索引\n",
        "        top_indices = np.argsort(cosine_differences)\n",
        "\n",
        "        # 判断前1、2、3、5个选项是否正确\n",
        "        if top_indices[0] == answer:\n",
        "            correct_1 += 1\n",
        "        if top_indices[1] == answer:\n",
        "            correct_2 += 1\n",
        "        if top_indices[2] == answer:\n",
        "            correct_3 += 1\n",
        "\n",
        "    # 计算前1、2、3、5的准确率\n",
        "    acc_1 = correct_1 / len(analogy_data['stem'])\n",
        "    acc_2 = correct_2 / len(analogy_data['stem'])\n",
        "    acc_3 = correct_3 / len(analogy_data['stem'])\n",
        "    # acc_5 = correct_5 / len(analogy_data['stem'])\n",
        "\n",
        "    return acc_1, acc_2, acc_3"
      ],
      "metadata": {
        "id": "u5U1MfHkOhNH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 导入数据，评估数据"
      ],
      "metadata": {
        "id": "3RDdoB48C8Wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "def data_load():\n",
        "  analogy_dataset = load_dataset(\"relbert/analogy_questions\",\"bats\")\n",
        "  print(analogy_dataset['test'][:2])\n",
        "  qqp_dataset = load_dataset(\"glue\", \"qqp\")\n",
        "  print(qqp_dataset['train'][:10])\n",
        "  return analogy_dataset['test'][:500],qqp_dataset['train'][:500]"
      ],
      "metadata": {
        "id": "zEDh7SVeOlKq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ana,qqp=data_load()\n",
        "\n",
        "acc_1, acc_2, acc_3=evaluate_analogy(model,ana)\n",
        "acc, precision, recall=evaluate_qqp(model,qqp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f0tmlZuXa9uS",
        "outputId": "10103b82-9c92-4c21-a252-518ef3ece4d8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'stem': [['hitler', 'dictator'], ['rousseau', 'writer']], 'answer': [0, 3], 'choice': [[['strauss', 'composer'], ['kepler', 'hegel'], ['wagner', 'beethoven'], ['ecuador', 'spanish']], [['cattle', 'calf'], ['edison', 'hawking'], ['rembrandt', 'picasso'], ['hegel', 'philosopher']]], 'prefix': ['./cache/BATS_3.0/3_Encyclopedic_semantics/E05 [name - occupation].txt', './cache/BATS_3.0/3_Encyclopedic_semantics/E05 [name - occupation].txt']}\n",
            "{'question1': ['How is the life of a math student? Could you describe your own experiences?', 'How do I control my horny emotions?', 'What causes stool color to change to yellow?', 'What can one do after MBBS?', 'Where can I find a power outlet for my laptop at Melbourne Airport?', \"How not to feel guilty since I am Muslim and I'm conscious we won't have sex together?\", 'How is air traffic controlled?', 'What is the best self help book you have read? Why? How did it change your life?', \"Can I enter University of Melbourne if I couldn't achieve the guaranteed marks in Trinity College Foundation?\", 'Do you need a passport to go to Jamaica from the United States?'], 'question2': ['Which level of prepration is enough for the exam jlpt5?', 'How do you control your horniness?', 'What can cause stool to come out as little balls?', 'What do i do after my MBBS ?', 'Would a second airport in Sydney, Australia be needed if a high-speed rail link was created between Melbourne and Sydney?', \"I don't beleive I am bulimic, but I force throw up atleast once a day after I eat something and feel guilty. Should I tell somebody, and if so who?\", 'How do you become an air traffic controller?', 'What are the top self help books I should read?', 'University of the Philippines: If I take a second BFA in the UP College of Fine Arts, can I be exempted from gen. ed. or core subjects?', 'How can I move to Jamaica?'], 'label': [0, 1, 0, 1, 0, 0, 0, 1, 0, 0], 'idx': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Analogy Task - Top 1 Accuracy: {acc_1*100:.2f}%\")\n",
        "print(f\"Analogy Task - Top 2 Accuracy: {(acc_2+acc_1)*100:.2f}%\")\n",
        "print(f\"Analogy Task - Top 3 Accuracy: {(acc_2+acc_1+acc_3)*100:.2f}%\")\n",
        "\n",
        "# 打印 qqp 任务的准确率、精确度和召回率\n",
        "print(f\"QQP Task - Accuracy: {acc*100:.2f}%\")\n",
        "print(f\"QQP Task - Precision: {precision*100:.2f}%\")\n",
        "print(f\"QQP Task - Recall: {recall*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnnohVPbpY6w",
        "outputId": "4a275f8b-f8ca-459a-a1cb-56c4030e8cf1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analogy Task - Top 1 Accuracy: 36.40%\n",
            "Analogy Task - Top 2 Accuracy: 66.00%\n",
            "Analogy Task - Top 3 Accuracy: 80.40%\n",
            "QQP Task - Accuracy: 70.20%\n",
            "QQP Task - Precision: 57.45%\n",
            "QQP Task - Recall: 73.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NsenA-pKpXnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import words\n",
        "\n",
        "# 下载词汇列表\n",
        "nltk.download('words')\n",
        "\n",
        "# 获取英文单词列表\n",
        "word_list = words.words()\n",
        "print(word_list[:10])  # 打印前10个单词"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "H1OwJY35hUKH",
        "outputId": "610e15d6-d9be-4542-e4b7-eee4f9172155"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'a', 'aa', 'aal', 'aalii', 'aam', 'Aani', 'aardvark', 'aardwolf', 'Aaron']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    }
  ]
}